# Εικονικός Βοηθός ΣΕΠ
Ανάπτυξη ενός εικονικού βοηθού με αντικείμενο τον Σχολικό Επαγγελματικό Προσανατολισμό (ΣΕΠ)
## [6oς Πανελλήνιος Διαγωνισμός Ανοιχτών Τεχνολογιών](https://openedtech.ellak.gr/) 
### Ομάδα: Τι θα γίνω όταν μεγαλώσω
### Σχολείο: 2ο ΕΠΑΛ Καβάλας (Εσπερινό)
### Μαθητές:
- Θωμαΐδου Ελένη
- Κοντογιάννης Ιωάννης
- Κόκκινος Ιωάννης
- Κερεφίδης Χρήστος
- Μανγκλι Τζουλιάνο
- Τοραμανίδης Κωνσταντίνος
- Χαμπαρλή Αναστασία
- Λόλακα Αθηνά
### Εκπαιδευτικός: Δαγκουλής Ιωάννης
> [!NOTE]
> **Ευχαριστούμε τις υπηρεσίες διαδικτύου της ΕΛΛΑΚ για την παροχή δωρεάν χώρου φιλοξενίας για το LLM meltemi**
>
> Επίσης ευχαριστούμε το 1 Ε.Κ. Καβάλας για την παροχή ασύρματης ζεύξης και δυνατότητας δοκιμών σε εξυπηρετητή του σχολείου

## Ιδέα
Μετά από συζήτηση στη τάξη και μελέτη διάφορων προτάσεων καταλήξαμε στην πρόταση της δημιουργίας ενός εικονικού βοηθού ΣΕΠ. 
### Υπάρχουσα κατάσταση
Ο θεσμός του ΣΕΠ υποστηρίζεται στην Δευτεροβάθμια Εκπαίδευση μέσω των υπευθύνων ΣΕΠ ανά ΔΔΕ. Παράλληλα σχεδόν κάθε χρόνο αποστέλλονται οδηγίες από το ΙΕΠ για την εφαρμογή του ΣΕΠ στην Γ γυμνασίου για την εφαρμογή του στο πλαίσιο των Εργαστηρίων Δεξιοτήτων. Ο Σχολικός Επαγγελματικός Προσανατολισμός είναι ένα πολύ σημαντικό ζήτημα και καθοριστικό για την μετέπειτα πορεία στην ζωή του κάθε μαθητή
### Προβλήμα – ανάγκη
Μέρος της εφαρμογής του ΣΕΠ είναι η διενέργεια αυτοαξιολογήσεων από τους μαθητές προκειμένου να αντληθούν περισσότερες πληροφορίες για την προσωπικότητα τους ώστε να να βοηθηθούν στην επιλογή του καταλληλότερου για αυτούς επαγγέλματος. Αυτά υλοποιούνται είτε 
μέσω γραπτών αυτοαξιολογήσεων είτε με ηλεκτρονικά ερωτηματολόγια. Θεωρούμε ότι η υλοποίηση των τεστ αυτοαξιολόγησης μέσω ενός εικονικου βοηθού μπορεί να βοηθήσει συμπληρωματικά το έργο ενός Υπευθύνου ΣΕΠ καθώς κάνει την διαδικασία περισσότερο ελκυστική στον μαθητή ενώ παράλληλα μπορεί να εξαχθούν οι καταάλληλες συμβουλές μέσω ενός μοντέλου τεχνητής νοημοσύνης
### Προτεινόμενη λύση
Σκοπός μας είναι η δημιουργία ενός εικονικού βοηθού ΣΕΠ με εργαλεία ανοικτού λογισμικού. Για τον σκοπό αυτό θα χρειαστεί να υλοποιήσουμε μία εφαρμογή για κινητά (android) που θα λειτουργεί ώς frontend για τον χρήστη. Αυτή η εφαρμογή θα υλοποιηθεί με το app inventor. Επιπλέον θα υλοποιηθεί ένα μοντέλο τεχνητής νοημοσύνης βασισμένο πάνω σε σύγχρονες τεχονολογίες ανοικτού κώδικα. 
### Κόστος
Ενδεχομένως για την εκπαίδευση του μοντέλου καθώς και για την λειτουργία του server που θα παρέχει υπηρεσίες ερωτοαπαντήσεων θα πρέπει να νοικιαστεί χώρος φιλοξενίας σε εταιρίες εξιδικευμένες για αυτό τον σκοπό. Το ποσό ετησίως εκτιμάται ότι μπορεί να ανέλθει στα 200 ευρώ. Εναλλακτικά θα μπορούσε να υλοποιηθεί η λύση χρήσης open hardware για την εκπαίδευση του μοντέλου, άλλα εξαρτάται από τις τελικές απαιτήσεις σε επεξεργαστική ισχύ.
## Υλοποίηση
![diagram](https://github.com/2epalKavalas/careerAdvisor/assets/152330230/0708c63d-9976-4c6c-a222-9b196e9b31a1)
Μετά από έρευνα καταλήξαμε ότι για την υλοποίηση θα έπρεπε να δημιουργηθεί μία εφαρμογή πελάτης που θα χρησιμοποιείται για να θέτει ερωτήματα και να λαμβάνει απαντήσεις σε έναν εξυπηρετητή που αντιπροσωπεύει ένα γλωσσικό μοντέλο. Αυτή η αρχιτεκτονική είναι η πλέον συνήθης σε τέτοιου είδους περιπτώσεις, π.χ. GPT κ.α. 
### [εφαρμογή πελάτης](https://blogs.e-me.edu.gr/hive-onasis-2024/) 
![hat_logo](https://github.com/2epalKavalas/careerAdvisor/assets/152330230/aed7d7cd-c0b3-49ee-9eb3-3fb1d1ede2d5)

Για την εφαρμογή πελάτης προτάθηκε να λειτουργεί μέσω κινητού ως εφαρμογή android, λόγω της ευκολίας χρήσης της και τις έξτρα δυνατότητες που παρέχει μία κινητή συσκευή στις μέρες μας. Επιπλέον προτιμηθηκε αυτή η λύση λόγω της σχετικής ευκολίας ανάπτυξης μίας τέτοιας εφαρμογής από μαθητές μέσω του περιβάλλοντος του app inventor. Το app inventor είναι ένα προγραμματιστικο περιβάλλον με τουβλάκια (blocks) που οδηγούν στην δημιουργία εφαρμογών για κινητά android. Διδάσκεται στην 1η λυκείου σε ΓΕΛ και ΕΠΑΛ. Με την χρήση του δημιουργήσαμε το πρόγραμμα πελάτη μέσω του οποίου επικοινωνεί ο χρήστης με το μοντέλο. Δίνεται η δυνατότητα επικοινωνίας και με φωνητική ομιλία χρησιμοποιώντας αντίστοιχη υπηρεσία της Google από τα κινητά. Για την υλοποίηση του χρησιμοποιήσαμε διάφορους components. Η πιο μεγάλη πρόκληση ήταν η επικοινωνία με το μοντέλο μέσω api κλήσεων, που προϋπέθετε την χρήση δεδομένων json. Με την βοήθεια του οδηγού https://ai2.appinventor.mit.edu/reference/blocks/dictionaries.html και τις αντίστοιχες οδηγίες του openai https://platform.openai.com/docs/api-reference/chat μπορέσαμε να πετύχουμε την επικοινωνία μεταξύ προγράμματος πελάτη και μοντέλου. Η εφαρμογή είναι διαθέσιμη στο app inventor gallery για όποιον θέλει να την μελετήσει ή/και να την τροποποιήσει.

[career Advisor](https://gallery.appinventor.mit.edu/?galleryid=5a3f0d04-7536-4602-8d14-53952176b193)

### Εξυπηρετητής - Γλωσσικό μοντέλο
Ο εξυπηρετητής αποτελεί μεγαλύτερη πρόκληση στην υλοποίηση του. Τα κύρια προβλήματα που συναντήσαμε ήταν τα εξής:
- Οι απαιτήσεις των μεγάλων γλωσσικών μοντέλων (LLMs) σε επεξεργαστική ισχύ και μνήμη είναι απαγορευτικές για έργα μικρού ή/και μηδενικού προυπολογισμού. Για τον λόγο αυτό και έχουν αναπτυχθεί αντίστοιχες υπηρεσίες cloud που κοστολογούν με συγκεκριμένο τρόπο αντίστοιχες υπηρεσίες
- επειδή πρόκειται για σχετικά νέα τεχνολογία, ήταν δύσκολο να βρεθούν ώριμα εργαλεία ανοικτού κώδικα που βοηθούν στην υλοποίηση αντίστοιχων εφαρμογών
- στην διάρκεια της ανάπτυξης και της μελέτης προέκυπταν νέα δεδομένα και εξελίξεις στο χώρο στα οποία θα έπρεπε να προσαρμοστεί η ομάδα

Αρχικά ασχοληθήκαμε με το μοντέλο LLAMA το οποίο παρέχεται απο την εταιρία META και θεωρείται σχετικά ανοικτό μοντέλο αν και υπάρχουν άρθρα που αμφισβητούν αυτή την θέση. Ένα από τα κύρια του προβλήματα επίσης ήταν ότι δεν υποστήρίζει εξ' αρχής ελληνικά, οπότε ήμασταν αρκετά προβληματισμένοι σχετικά με την απόδοση του σε πραγματικές συνθήκες ιδιαίτερα και μετά τις αρχικές δοκιμές. Στην πορεία όμως προέκυψε το meltemi, ένα γλωσσικό μοντέλο που βασίζεται στο mistral. Το meltemi αναπτύχθηκε από το Ινστιτούτο Γλώσσας και Επεξεργασίας του λόγου και προτιμήθηκε καθώς το μοντέλο έχει μετεκπαιδευτεί στην ελληνική γλώσσα. Σχετικά, https://opengov.ellak.gr/2024/03/29/meltemi-ena-elliniko-llm/, https://huggingface.co/ilsp.
'Οπως αναφερθήκαμε και πιο πριν, ένα βασικό πρόβλημα ήταν να βρεθεί ένας τρόπος ανάπτυξης και δοκιμών που δεν θα απαιτούσε υπέρμετρο κόστος. Ευτυχώς από τον Αυγουστο του 2023 έχει αναπτυχθεί το GGUF (GPT-Generated Unified Format), που υποστηρίζεται μέσω του περιβάλλοντος llama.cpp. Μέσω αυτών των εργαλείων είναι δυνατή η ανάπτυξη και η δοκιμή ενός γλωσσικού μοντέλου ακόμη και με την χρήση απλών CPU χωρίς αντίστοιχη χρήση καρτών γραφικών με ορισμένες απλοποιήσεις των LLMs που σίγουρα μειώνουν την αποδοτικότητα τους άλλα τα καθιστούν λειτουργικά ακόμα και με την χρήση ενός καθημερινού Η/Υ με σχετικά μεγάλη μνήμη RAM.
Ενα άλλο πρόβλημα ήταν να βρεθεί ένα εργαλείο που θα υλοποιεί την λύση του llama.cpp και παράλληλα να παρέχει ένα περιβάλλον δοκιμής διαλόγων που να είναι προσιτό από την ομάδα ανάπτυξης. Ευτυχώς έχουν αναπτυχθεί σχετικά εργαλεία, όπου μετά από σχετικές δοκιμές επιλέξαμε το text generation webui

#### Εργαλείο https://github.com/oobabooga/text-generation-webui

##### Περιγραφή
Πρόκειται για ένα εργαλείο που παρέχει πρόσβαση μέσω διαδικτύου σε ιστοσελίδες, μέσω του οποίου είναι δυνατή η παραμετροποίηση και η διενέργεια δοκιμών σε ένα μεγάλο πλήθος μοντέλων. Επιπλέον παρέχεται ένα συμβατό με openai api για κλήσεις του μοντέλου μέσω api από προγράμματα πελάτη.

##### Οδηγός χρήσης (linux):
Αρχικά αντιγράφουμε μέσω git clone τον κώδικα, και "τρέχουμε" το πρόγραμμα δίνοντας από το τερματικό την εντολή ./start_linux.sh --api. Μετά την εκτέλεση θα μας δοθεί η δυνατότητα διαχείρισης του μοντέλου, μέσω ενός web περιβάλλοντος που θα έχουμε πρόσβαση από το τοπικό περιβάλλον του Η/Υ στην διεύθυνση http://127.0.0.1:7860. Παράλληλα μέσω της παραμέτρου api μπορούμε να δώσουμε την δυνατότητα κλήσεων μέσω συμβατού προτύπου openai api στην αντίστοιχη διεύθυνση 127.0.0.1:5000
Με την χρήση του τοπικού περιβάλλοντος μπορούμε να ρυθμίσουμε το μοντέλο μας έτσι ώστε να το "φορτώσουμε" για να χρησιμοποιηθεί στις ανταπαντήσεις.
Στην περίπτωση μας χρησιμοποιήθηκε η έκδοση https://huggingface.co/ilsp/Meltemi-7B-Instruct-v1-GGUF. Επιλέχθηκε το συγκεκριμένο λόγω περιορισμών στο υλικό. Ο λόγος είναι ότι για την φόρτωση και λειτουργία ενός μοντέλου, απαιτείται ισχυρή επεξεργαστική ισχύ με την χρήση μονάδων καρτών γραφικών που δεν διαθέτει ο μέσος χρήστης. Για την πρόσβαση σε τέτοιες υπηρεσίες υπάρχει αντίστοιχο κόστος. Για αυτή την περίπτωση έχει αναπτυχθεί η βιβλιοθήκη λογισμικου GGUF που παρέχει την δυνατότητα λειτουργίας ενός μοντέλου ακόμη και σε απλές CPU, θυσιάζοντας εν μέρει την αποτελεσματικότητα του μοντέλου. Μετά από δοκιμές επιλέχθηκε η έκδοση meltemi-instruct-v1_q5_K_M.bin γιατί το πιο απλό meltemi-instruct-v1_q3_K_M.bin δεν απέδιδε καλά.
Το μοντέλο φορτώθηκε και αρχικά δοκιμάστηκε μέσω του περιβάλλοντος web-gui φώτο, ενώ στην συνέχεια χρησιμοποιήθηκε το api μέσω της εφαρμογής του app inventor. Μέσω αρκετών πειραματισμών καταλήξαμε στο καταλληλότερη ρύθμιση βάση και των δυνατοτήτων. Το αποτέλεσμα κρίνεται σχετικά ικανοποιητικό για πειραματική χρήση. Τα κύρια προβλήματα που υπάρχουν μέχρι στιγμής είναι τα εξής:
## Περιβάλλον ανάπτυξης δοκιμαστική φάση
- Αρχικά οι δοκιμές του meltemi έγιναν σε ένα laptop με χαρακτηριστικά i5-7200U 16GB RAM. Αφού ενεργοποιήθηκε το webui και ρυθμίστηκε το μοντέλο έγιναν δοκιμές μέσω του web περιβάλλοντος. ![εικόνα](https://github.com/2epalKavalas/careerAdvisor/assets/152330230/d200f2ae-f0d8-44c3-92dd-f72f647fc584)
 Μετά από διάφορες τροποποιήσεις στην παραμετροποίηση και στην δοκιμή των δύο εκδόσεων των μοντέλων gguf του meltemi, προτιμήθηκε το meltemi-instruct-v1_q5_K_M.bin καθώς το meltemi-instruct-v1_q3_K_M.bin παρουσίαζε διάφορες δυσλειτουργίες ενώ το μέγεθος του meltemi-instruct-v1_q5_K_M.bin δεν θεωρήθηκε απαγορευτικό.
- Στην συνέχεια έπρεπε να γίνει η διασύνδεση του μοντέλου με την εφαρμογή app inventor. Για τον σκοπό αυτό θα έπρεπε να είναι δυνατή η πρόσβαση μέσω διαδικτύου σε τοπικό Η/Υ. Για αυτή την ανάγκη χρησιμοποιήσαμε ένα πρόγραμμα tunnelling το localtunnel https://github.com/localtunnel/localtunnel, μέσω του οποίου ήταν δυνατή η προσβαση της εφαρμογής app inventor.

Τα κύρια προβλήματα που καταγράφησαν ήταν τα εξής:
- αργή ανταπόκριση
- μη ολοκλήρωση μίας συνεδρίας μέχρι την επιλογή επαγγέλματος
- κάποιες φορές οι απαντήσεις δεν επιστρέφουν, (χάνονται;)
- κάποιες φορές άσχετες απαντήσεις σε σχέση με το θέμα
- κάποιες φορές απαντήσεις στα αγγλικά

## Περιβάλλον Λειτουργίας και δοκιμών

Προκειμένου να έχουν πρόσβαση όλα τα μέλη της ομάδας στο περιβάλλον ανάπτυξης και λειτουργίας, είναι απαραίτητο ο server να φιλοξενείται σε Η/Υ στον οποίο υπάρχει πρόσβαση 24/24/365. Δυστυχώς κάτι τέτοιο δεν παρέχεται δωρεάν αυτή την στιγμή, ακόμη και σε πειραματική φάση μετά από σχετική έρευνα. (colab, hugging_face κ.α.). Ευτυχώς το ΕΛ/ΛΑΚ μας παρείχε υποστήριξη διαθέτοντας μας αντίστοιχη υπηρεσία στο cloud με αποτέλεσμα να στηθεί επιτυχώς το γλωσσικό μοντέλο στον αντίστοιχο server. Έτσι τώρα είναι προσβάσιμο 24/24/365 το μοντέλο και διαθέσιμο για δοκιμές σε όποιον ενδιαφέρεται. Αρκεί να κατεβάσετε την εφαρμογή που κατασκευάσαμε μέσω του app inventor από την [ιστοσελίδα της ομάδας](https://blogs.e-me.edu.gr/hive-onasis-2024/)

## Μελλοντικά βήματα
- Βελτίωση του περιβάλλοντος λειτουργίας και εμφάνισης της εφαρμογής
- Εκπαίδευση του μοντέλου με συγκεκριμένα δεδομένα
- Εξαγωγή δεδομένων από την συζήτηση του χρήστη με το bot
- Παρακολούθηση συνομιλίας μεταξύ χρήστη και bot για εξαγωγή συμπερασμάτων συμπεριφοράς
- Δημιουργία φόρμας ανατροφοδότησης από τον χρήστη 

## Χρήσιμοι σύνδεσμοι
 
- https://huggingface.co/ilsp/Meltemi-7B-Instruct-v1-GGUF

- https://www.esos.gr/arthra/76688/odigies-gia-tin-ylopoiisi-toy-sholikoy-epaggelmatikoy-prosanatolismoy-tis-g-taxis

